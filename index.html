<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tetris Video to Tetofu Converter</title>
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<style>
    :root { --bg: #1a1a2e; --primary: #4b4b7c; --accent: #00a0f0; --text: #e0e0e0; }
    body { background-color: var(--bg); color: var(--text); font-family: 'Noto Sans JP', sans-serif; padding: 20px; margin: 0; }
    h1, h2 { border-bottom: 2px solid var(--primary); padding-bottom: 10px; }
    .container { max-width: 1000px; margin: 0 auto; }
    .panel { background: rgba(255,255,255,0.05); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid var(--primary); }
    .controls { display: grid; gap: 15px; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); }
    button { background: var(--accent); color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 16px; font-weight: bold; }
    button:disabled { background: #555; cursor: not-allowed; }
    button:hover:not(:disabled) { opacity: 0.9; }
    input[type="file"] { padding: 10px; background: rgba(0,0,0,0.3); border-radius: 4px; width: 100%; box-sizing: border-box; }
    
    .progress-section { margin-top: 20px; }
    progress { width: 100%; height: 20px; border-radius: 10px; }
    
    #logArea { background: #000; border: 1px solid #555; height: 200px; overflow-y: scroll; font-family: monospace; white-space: pre-wrap; padding: 10px; font-size: 12px; margin-top: 10px; }
    .log-info { color: #4db8ff; } .log-warn { color: #ffff00; } .log-error { color: #ff4444; } .log-success { color: #00ff00; }

    .result-link { font-size: 1.2em; word-break: break-all; background: #000; padding: 15px; border-radius: 5px; border: 1px solid var(--accent); }
    a { color: var(--accent); }

    /* Hidden elements for processing */
    #videoPlayer, #processCanvas { display: none; }
</style>
</head>
<body>

<div class="container">
    <h1>Tetris Video to Tetofu (v2)</h1>
    <p>動画を解析し、P1/P2の時系列データを統合してテト譜リンクを生成します。</p>

    <div class="panel">
        <h2>1.準備</h2>
        <div class="controls">
            <div id="modelInputContainer">
                <label>1.ONNXモデル (tetris.onnx)</label>
                <input type="file" id="modelInput" accept=".onnx">
            </div>
            <div>
                <label>2.解析する動画 (MP4/WebM)</label>
                <input type="file" id="videoInput" accept="video/*">
            </div>
        </div>
        <div style="margin-top: 15px;">
            <label>解析サンプル数: <input type="number" id="sampleCount" value="10" step="1" style="width: 60px;"></label>
            <span style="font-size: 0.8em; color: #aaa;">※ 1イベントあたりの解析回数</span>
        </div>
    </div>

    <div class="panel">
        <h2>2. 実行</h2>
        <button id="startBtn" disabled>解析開始</button>
        <button id="stopBtn" disabled style="background-color: #f00;">停止</button>
        
        <div class="progress-section">
            <div>P1 Progress: <span id="p1Status">待機中</span></div>
            <progress id="p1Progress" value="0" max="100"></progress>
        </div>
        <div class="progress-section">
            <div>P2 Progress: <span id="p2Status">待機中</span></div>
            <progress id="p2Progress" value="0" max="100"></progress>
        </div>
        
        <h3>System Log</h3>
        <div id="logArea"></div>
    </div>

    <div class="panel hidden" id="resultPanel" style="display:none;">
        <h2>3. 結果</h2>
        <div class="result-link">
            <a id="finalLink" href="#" target="_blank">生成中...</a>
        </div>
    </div>
</div>

<video id="videoPlayer" muted playsinline></video>
<canvas id="processCanvas"></canvas>

<script>
// ==========================================
//  Global Config & Variables
// ==========================================
const CONFIG = {
    // 1920x1080 scaling base for P1/P2 regions (Source 2)
    p1: {
        boardRect: { x: 304, y: 157, w: 366, h: 725 }, // Source 2: 670-304=366, 882-157=725
        nextCoords: [ {x:160, y:155}, {x:500, y:122}, {x:500, y:175}, {x:500, y:225}, {x:500, y:275}, {x:500, y:325} ]
    },
    p2: {
        boardRect: { x: 1257, y: 157, w: 363, h: 725 }, // Source 2: 1620-1257=363
        nextCoords: [ {x:790, y:155}, {x:1130, y:122}, {x:1130, y:175}, {x:1130, y:225}, {x:1130, y:275}, {x:1130, y:325} ]
    }
};

const CLASS_NAMES = ['null', 'G', 'S', 'Z', 'L', 'J', 'O', 'I', 'T'];
let session = null;
let isRunning = false;
let stopRequested = false;

// ==========================================
//  Image Processing Core (Ported from Source 2)
//  "画像認識のロジックは完全に移植し、あらゆる簡略化は許可しない"
// ==========================================

const SCAN_COLOR_PALETTE = { 'NULL': ['#000000', '#302838'], 'G': ['#999999', '#D8D8D8'], 'I': ['#019899', '#0199D5'], 'O': ['#999A02', '#F9B900'], 'T': ['#980099', '#871E88'], 'L': ['#996700', '#F56100'], 'J': ['#0000BB', '#004BA5'], 'S': ['#10971F', '#5CB523'], 'Z': ['#990000', '#DA1822'] };
const hexToRgb = (hex) => { const r = parseInt(hex.slice(1, 3), 16), g = parseInt(hex.slice(3, 5), 16), b = parseInt(hex.slice(5, 7), 16); return { r, g, b }; };
const PARSED_SCAN_COLORS = {};
for (const key in SCAN_COLOR_PALETTE) { PARSED_SCAN_COLORS[key] = SCAN_COLOR_PALETTE[key].map(hexToRgb); }
const colorDistanceSq = (c1, c2) => (Math.pow(c1.r - c2.r, 2) + Math.pow(c1.g - c2.g, 2) + Math.pow(c1.b - c2.b, 2));

function findClosestColor(r, g, b) { 
    const inputColor = { r, g, b };
    for (const nullColor of PARSED_SCAN_COLORS.NULL) { if (colorDistanceSq(inputColor, nullColor) < 6000) return null; } 
    for (const gColor of PARSED_SCAN_COLORS.G) { if (colorDistanceSq(inputColor, gColor) < 10000) return 'G'; } 
    let minDistance = Infinity, closestKey = null;
    const minoKeys = Object.keys(PARSED_SCAN_COLORS).filter(k => k !== 'NULL' && k !== 'G');
    for (const key of minoKeys) { 
        for (const targetColor of PARSED_SCAN_COLORS[key]) { 
            const distance = colorDistanceSq(inputColor, targetColor);
            if (distance < minDistance) { minDistance = distance; closestKey = key; } 
        } 
    } 
    return (minDistance > 25000) ? null : closestKey; 
}

function findClosestMinoOnly(r, g, b) { 
    const inputColor = { r, g, b };
    let minDistance = Infinity, closestKey = 'I'; 
    const minoKeys = Object.keys(PARSED_SCAN_COLORS).filter(k => k !== 'NULL' && k !== 'G');
    for (const key of minoKeys) { 
        for (const targetColor of PARSED_SCAN_COLORS[key]) { 
            const distance = colorDistanceSq(inputColor, targetColor);
            if (distance < minDistance) { minDistance = distance; closestKey = key; } 
        } 
    } 
    return closestKey;
}

function getAverageColorNonBlack(ctx, cx, cy, radius) {
    const startX = Math.max(0, Math.floor(cx - radius)), startY = Math.max(0, Math.floor(cy - radius)), diameter = Math.ceil(radius * 2), endX = Math.min(ctx.canvas.width, startX + diameter), endY = Math.min(ctx.canvas.height, startY + diameter), width = endX - startX, height = endY - startY;
    if (width <= 0 || height <= 0) return { r: 0, g: 0, b: 0 };
    const imageData = ctx.getImageData(startX, startY, width, height).data;
    let totalR = 0, totalG = 0, totalB = 0, count = 0;
    const radiusSq = radius * radius;
    const blackThreshold = 50;
    for (let y = 0; y < height; y++) {
      for (let x = 0; x < width; x++) {
        const dx = (startX + x) - cx;
        const dy = (startY + y) - cy;
        if (dx * dx + dy * dy <= radiusSq) {
          const i = (y * width + x) * 4;
          const r = imageData[i], g = imageData[i + 1], b = imageData[i + 2];
          if (r > blackThreshold || g > blackThreshold || b > blackThreshold) {
            totalR += r; totalG += g; totalB += b; count++;
          }
        }
      }
    }
    return count === 0 ? { r: 0, g: 0, b: 0 } : { r: totalR / count, g: totalG / count, b: totalB / count };
}

function processImageTo1080p(imgBitmap) {
    const srcW = imgBitmap.width;
    const srcH = imgBitmap.height;
    const targetAspect = 16 / 9;
    const srcAspect = srcW / srcH;
    let cropW, cropH, cropX, cropY;

    if (srcAspect > targetAspect) {
        cropH = srcH; cropW = srcH * targetAspect;
        cropX = (srcW - cropW) / 2; cropY = 0;
    } else {
        cropW = srcW; cropH = srcW / targetAspect;
        cropX = 0; cropY = (srcH - cropH) / 2;
    }

    const canvas = document.createElement('canvas');
    canvas.width = 1920; canvas.height = 1080;
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    ctx.drawImage(imgBitmap, cropX, cropY, cropW, cropH, 0, 0, 1920, 1080);
    return { canvas, cropData: { cropX, cropY, cropW, cropH } };
}

function extractCellPixels(sourceImgData, x, y, w, h) {
    const sw = sourceImgData.width;
    const ix = Math.floor(x), iy = Math.floor(y);
    const iw = Math.floor(w), ih = Math.floor(h);
    const data = new Uint8ClampedArray(iw * ih * 4);
    for (let row = 0; row < ih; row++) {
        const srcRowStart = ((iy + row) * sw + ix) * 4;
        const destRowStart = (row * iw) * 4;
        const rowPixels = sourceImgData.data.subarray(srcRowStart, srcRowStart + iw * 4);
        data.set(rowPixels, destRowStart);
    }
    return data;
}

function extractFeaturesJS(pixelsRGBA, w, h) {
    const numPixels = w * h;
    const feats = [];
    const bCh = new Float32Array(numPixels), gCh = new Float32Array(numPixels), rCh = new Float32Array(numPixels);
    const hCh = new Float32Array(numPixels), sCh = new Float32Array(numPixels), vCh = new Float32Array(numPixels);

    for (let i = 0; i < numPixels; i++) {
        const r = pixelsRGBA[i * 4], g = pixelsRGBA[i * 4 + 1], b = pixelsRGBA[i * 4 + 2];
        bCh[i] = b; gCh[i] = g; rCh[i] = r;
        const maxVal = Math.max(r, g, b), minVal = Math.min(r, g, b);
        const diff = maxVal - minVal;
        const v = maxVal;
        let s = (maxVal !== 0) ? (diff / maxVal) * 255 : 0;
        let h_val = 0;
        if (maxVal === minVal) h_val = 0;
        else if (maxVal === r) h_val = (60 * (g - b) / diff + 360) % 360;
        else if (maxVal === g) h_val = (60 * (b - r) / diff + 120) % 360;
        else if (maxVal === b) h_val = (60 * (r - g) / diff + 240) % 360;
        h_val = h_val / 2;
        vCh[i] = v; sCh[i] = s; hCh[i] = h_val;
    }

    const getStats = (arr) => {
        let sum = 0; for(let v of arr) sum += v;
        const mean = sum / arr.length;
        let sqDiffSum = 0; for(let v of arr) sqDiffSum += (v - mean) ** 2;
        return [mean, Math.sqrt(sqDiffSum / arr.length)];
    };

    const statsB = getStats(bCh), statsG = getStats(gCh), statsR = getStats(rCh);
    feats.push(statsB[0], statsB[1], statsG[0], statsG[1], statsR[0], statsR[1]);
    const statsH = getStats(hCh), statsS = getStats(sCh), statsV = getStats(vCh);
    feats.push(statsH[0], statsH[1], statsS[0], statsS[1], statsV[0], statsV[1]);

    const stepX = w / 4, stepY = h / 4;
    for (let ty = 0; ty < 4; ty++) {
        for (let tx = 0; tx < 4; tx++) {
            const sx = Math.floor(tx * stepX), sy = Math.floor(ty * stepY);
            const ex = Math.floor((tx + 1) * stepX), ey = Math.floor((ty + 1) * stepY);
            let sumB=0, sumG=0, sumR=0, count=0;
            for(let py=sy; py<ey; py++){
                for(let px=sx; px<ex; px++){
                    const idx = py * w + px;
                    if(idx < numPixels) { sumB += bCh[idx]; sumG += gCh[idx]; sumR += rCh[idx]; count++; }
                }
            }
            if(count===0) feats.push(0,0,0);
            else feats.push(sumB/count, sumG/count, sumR/count);
        }
    }

    const cx = Math.floor(w/2), cy = Math.floor(h/2), cw = Math.floor(w/4), ch = Math.floor(h/4);
    const startX = cx - cw, endX = cx + cw, startY = cy - ch, endY = cy + ch;
    let cSumB=0, cSumG=0, cSumR=0, cCount=0;
    for(let py=startY; py<endY; py++){
        for(let px=startX; px<endX; px++){
            if(px>=0 && px<w && py>=0 && py<h){
                const idx = py * w + px;
                cSumB += bCh[idx]; cSumG += gCh[idx]; cSumR += rCh[idx]; cCount++;
            }
        }
    }
    if(cCount===0) feats.push(0,0,0);
    else feats.push(cSumB/cCount, cSumG/cCount, cSumR/cCount);

    return new Float32Array(feats);
}
// --- 新規追加: ONNXを使わずNext/Holdのみを高速判定する関数 ---
function analyzeNextHoldOnly(canvas, originalBitmap, cropData, config) {
    // 3. Next/Hold Logic (analyzePlayerRawからロジックを流用・軽量化)
    const nextQueue = [];
    let holdMino = null;
    const rawCropCanvas = document.createElement('canvas');
    rawCropCanvas.width = cropData.cropW; rawCropCanvas.height = cropData.cropH;
    const rawCtx = rawCropCanvas.getContext('2d', { willReadFrequently: true });
    rawCtx.drawImage(originalBitmap, cropData.cropX, cropData.cropY, cropData.cropW, cropData.cropH, 0, 0, cropData.cropW, cropData.cropH);
    const currentScale = cropData.cropW / 1280;
    const radius = 5 * currentScale;

        for (let i = 0; i < config.nextCoords.length; i++) {
        const coord = config.nextCoords[i];
        const avgColor = getAverageColorNonBlack(rawCtx, coord.x * currentScale, coord.y * currentScale, radius);
        if (i === 0) {
            const isBlack = avgColor.r < 50 && avgColor.g < 50 && avgColor.b < 50;
            if (isBlack) holdMino = null;
            else holdMino = findClosestMinoOnly(avgColor.r, avgColor.g, avgColor.b);
        } else {
            const isBlack = avgColor.r < 50 && avgColor.g < 50 && avgColor.b < 50;
            if (i === 1 && isBlack) break;
            const foundMino = findClosestMinoOnly(avgColor.r, avgColor.g, avgColor.b);
            if (foundMino) nextQueue.push(foundMino);
        }
    }
    return { hold: holdMino, next: nextQueue };
}

// プレイヤー1人分の解析を実行し、生データを返す（後で多数決する）
async function analyzePlayerRaw(canvas, originalBitmap, cropData, config) {
    const ctx = canvas.getContext('2d');
    const boardRect = config.boardRect;
    const boardImgData = ctx.getImageData(boardRect.x, boardRect.y, boardRect.w, boardRect.h);
    const cellW = boardRect.w / 10;
    const cellH = boardRect.h / 20;
    
    // 1. Classic Logic (Color distance)
    const classicBoard = [];
    const blockWidthPx = cellW, blockHeightPx = cellH;
    for (let r = 0; r < 20; r++) {
        const row = [];
        for (let c = 0; c < 10; c++) {
            const sampleX = boardRect.x + (c + 0.5) * blockWidthPx;
            const sampleY = boardRect.y + (r + 0.5) * blockHeightPx;
            const sampleSize = Math.max(1, Math.floor(blockWidthPx * 0.25));
            const imageData = ctx.getImageData(sampleX - sampleSize / 2, sampleY - sampleSize / 2, sampleSize, sampleSize).data;
            let avgR = 0, avgG = 0, avgB = 0;
            for (let i = 0; i < imageData.length; i += 4) { avgR += imageData[i]; avgG += imageData[i+1]; avgB += imageData[i+2]; }
            const pixelCount = imageData.length / 4;
            avgR /= pixelCount; avgG /= pixelCount; avgB /= pixelCount;
            row.push(findClosestColor(avgR, avgG, avgB));
        }
        classicBoard.push(row);
    }

    // 2. ONNX Logic
    const batchFeatures = [];
    for (let r = 0; r < 20; r++) {
        for (let c = 0; c < 10; c++) {
            const x = c * cellW, y = r * cellH;
            const cellPixels = extractCellPixels(boardImgData, x, y, cellW, cellH);
            const feats = extractFeaturesJS(cellPixels, Math.floor(cellW), Math.floor(cellH));
            batchFeatures.push(feats);
        }
    }

    const flatInput = new Float32Array(batchFeatures.length * 63);
    for (let i = 0; i < batchFeatures.length; i++) { flatInput.set(batchFeatures[i], i * 63); }
    const tensor = new ort.Tensor('float32', flatInput, [200, 63]);
    const results = await session.run({ [session.inputNames[0]]: tensor }, [session.outputNames[0]]);
    const labelData = results[session.outputNames[0]].data;

    const recognizedBoard = [];
    for (let i = 0; i < 200; i++) {
        const r = Math.floor(i / 10), c = i % 10;
        if(c === 0) recognizedBoard.push([]);
        const label = CLASS_NAMES[Number(labelData[i])];
        recognizedBoard[r].push((label === 'null') ? null : label);
    }

    // Merge Logic (Correction)
    for (let r = 0; r < 20; r++) {
        const onnxRow = recognizedBoard[r];
        const isOnlyNullOrG = onnxRow.every(cell => cell === null || cell === 'G');
        if (isOnlyNullOrG) {
            const gCountOnnx = onnxRow.filter(cell => cell === 'G').length;
            if (gCountOnnx !== 10) {
                const classicRow = classicBoard[r];
                const gCountClassic = classicRow.filter(cell => cell === 'G').length;
                const nullCountClassic = classicRow.filter(cell => cell === null).length;
                if (gCountClassic === 9 && nullCountClassic === 1) {
                    recognizedBoard[r] = [...classicRow];
                }
            }
        }
    }

    // 3. Next/Hold Logic
    const nextQueue = [];
    let holdMino = null;
    const rawCropCanvas = document.createElement('canvas');
    rawCropCanvas.width = cropData.cropW; rawCropCanvas.height = cropData.cropH;
    const rawCtx = rawCropCanvas.getContext('2d', { willReadFrequently: true });
    rawCtx.drawImage(originalBitmap, cropData.cropX, cropData.cropY, cropData.cropW, cropData.cropH, 0, 0, cropData.cropW, cropData.cropH);
    const currentScale = cropData.cropW / 1280;
    const radius = 5 * currentScale;

        for (let i = 0; i < config.nextCoords.length; i++) {
        const coord = config.nextCoords[i];
        const avgColor = getAverageColorNonBlack(rawCtx, coord.x * currentScale, coord.y * currentScale, radius);
        if (i === 0) {
            const isBlack = avgColor.r < 50 && avgColor.g < 50 && avgColor.b < 50;
            if (isBlack) holdMino = null;
            else holdMino = findClosestMinoOnly(avgColor.r, avgColor.g, avgColor.b);
        } else {
            const isBlack = avgColor.r < 50 && avgColor.g < 50 && avgColor.b < 50;
            if (i === 1 && isBlack) break;
            const foundMino = findClosestMinoOnly(avgColor.r, avgColor.g, avgColor.b);
            if (foundMino) nextQueue.push(foundMino);
        }
    }

    // 戻り値: 生の盤面 (20x10), Hold, Next
    // FullBoard化やGarbage処理はここでは行わず、多数決後にクリーンアップする
    return { board: recognizedBoard, hold: holdMino, next: nextQueue };
}


// ==========================================
//  Application Logic (Video Control & Voting)
// ==========================================

// 多数決用のクラス
class VoteAggregator {
    constructor() {
        this.reset();
    }
    reset() {
        // [y][x] = Map<Color, Count>
        this.votes = Array.from({length: 20}, () => Array.from({length: 10}, () => ({})));
        this.count = 0;
    }
    add(board) {
        this.count++;
        for(let y=0; y<20; y++){
            for(let x=0; x<10; x++){
                const val = board[y][x] || 'null';
                this.votes[y][x][val] = (this.votes[y][x][val] || 0) + 1;
            }
        }
    }
    getWinnerBoard() {
        if(this.count === 0) return null;
        const result = [];
        for(let y=0; y<20; y++){
            const row = [];
            for(let x=0; x<10; x++){
                let maxVote = -1;
                let winner = null;
                for(const [val, cnt] of Object.entries(this.votes[y][x])){
                    if(cnt > maxVote) { maxVote = cnt; winner = val; }
                }
                row.push(winner === 'null' ? null : winner);
            }
            result.push(row);
        }
        return result;
    }
}

// ログ出力
function log(msg, type='info') {
    const logArea = document.getElementById('logArea');
    const div = document.createElement('div');
    div.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
    div.className = `log-${type}`;
    logArea.appendChild(div);
    logArea.scrollTop = logArea.scrollHeight;
}

// セットアップ
const modelInput = document.getElementById('modelInput');
const videoInput = document.getElementById('videoInput');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const p1Progress = document.getElementById('p1Progress');
const p2Progress = document.getElementById('p2Progress');

async function loadModelBuffer(buffer) {
    try {
        session = await ort.InferenceSession.create(buffer, { executionProviders: ['wasm'] });
        log("モデルロード完了", 'success');
        checkReady();
    } catch (e) {
        log("モデルロード失敗: " + e.message, 'error');
    }
}

modelInput.addEventListener('change', async (e) => {
    if(e.target.files[0]) {
        const buffer = await e.target.files[0].arrayBuffer();
        loadModelBuffer(buffer);
    }
});

window.addEventListener('DOMContentLoaded', async () => {
    try {
        const res = await fetch('./tetris.onnx');
        if (res.ok) {
            log("tetris.onnx を自動検出しました。ロード中...", 'info');
            const buffer = await res.arrayBuffer();
            loadModelBuffer(buffer);
            const container = document.getElementById('modelInputContainer');
            if (container) container.style.display = 'none';
        }
    } catch (e) { console.log('Auto-load skipped'); }
});


videoInput.addEventListener('change', checkReady);

function checkReady() {
    if(session && videoInput.files.length > 0) {
        startBtn.disabled = false;
    }
}

// メイン処理ループ
startBtn.addEventListener('click', async () => {
    isRunning = true;
    stopRequested = false;
    startBtn.disabled = true;
    stopBtn.disabled = false;
    
    const file = videoInput.files[0];
    const url = URL.createObjectURL(file);
    const video = document.getElementById('videoPlayer');
    const canvas = document.getElementById('processCanvas');
    video.src = url;

    try {
        await new Promise(r => { video.onloadedmetadata = r; });
        const duration = video.duration;
        log(`動画読み込み完了: ${duration.toFixed(1)}秒`, 'info');
        
        // Canvasサイズ設定 (1920x1080処理のため、一時的に設定)
        canvas.width = 1920; 
        canvas.height = 1080;

        const p1Timeline = await processPlayer('p1', video, duration);
        if(stopRequested) return;
        const p2Timeline = await processPlayer('p2', video, duration);
        if(stopRequested) return;

        log("データ統合中...", 'info');
        const urlParams = generateFumenUrl(p1Timeline, p2Timeline);
        
        document.getElementById('finalLink').href = urlParams;
        document.getElementById('finalLink').textContent = urlParams;
        document.getElementById('resultPanel').style.display = 'block';
        log("完了しました！", 'success');

    } catch (e) {
        log("処理エラー: " + e.stack, 'error');
    } finally {
        isRunning = false;
        startBtn.disabled = false;
        stopBtn.disabled = true;
    }
});

stopBtn.addEventListener('click', () => {
    stopRequested = true;
    log("停止リクエスト...", 'warn');
});

// プレイヤーごとの解析ループ (Phase 1: 高速スキャン, Phase 2: 詳細解析)
async function processPlayer(playerId, video, duration) {
    log(`${playerId.toUpperCase()} 解析開始...`, 'info');
    const progressEl = document.getElementById(`${playerId}Progress`);
    const statusEl = document.getElementById(`${playerId}Status`);

    // --- Phase 1: イベント境界の検出 (0.05秒間隔) ---
    log(`${playerId.toUpperCase()} Phase 1: タイムラインスキャン中...`, 'info');
    const scanStep = 0.05;
    const events = []; // { start, end }
    
    let lastEventTime = 0;
    let prevHold = null;
    let prevNext = [];

    // ヘルパー: ネクスト配列の差分数をカウント
    const getDiffCount = (a1, a2) => {
        if(!a1 || !a2) return 99;
        let diff = Math.abs(a1.length - a2.length);
        const len = Math.min(a1.length, a2.length);
        for(let i=0; i<len; i++) { if(a1[i] !== a2[i]) diff++; }
        return diff;
    };

    for(let t = 0; t < duration; t += scanStep) {
        if(stopRequested) break;
        video.currentTime = t;
        await new Promise(r => { video.onseeked = r; });

        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = video.videoWidth; tempCanvas.height = video.videoHeight;
        const tempCtx = tempCanvas.getContext('2d');
        tempCtx.drawImage(video, 0, 0);
        
        // 軽量解析 (ONNXなし)
        const { cropData } = processImageTo1080p(tempCanvas);
        const { hold, next } = analyzeNextHoldOnly(null, tempCanvas, cropData, CONFIG[playerId]);

        if (t === 0) {
            prevHold = hold; prevNext = next;
            continue;
        }

        // 変化判定: Hold変化 または Nextが2つ以上変化
        const diff = getDiffCount(prevNext, next);
        if (hold !== prevHold || diff >= 2) {
            // イベント確定
            events.push({ start: lastEventTime, end: t });
            lastEventTime = t;
            prevHold = hold; prevNext = next;
        }

        const pct = Math.floor((t / duration) * 50); // Phase 1は50%まで
        progressEl.value = pct;
        statusEl.textContent = `Scanning... ${t.toFixed(1)}s`;
    }
    // 最後の区間
    events.push({ start: lastEventTime, end: duration });

    // --- Phase 2: 区間ごとの詳細解析 (10分割 & 多数決) ---
    log(`${playerId.toUpperCase()} Phase 2: 盤面詳細解析中 (${events.length} events)...`, 'info');
    const timeline = [];
    const sampleVal = document.getElementById('sampleCount').value;
    const SAMPLES_PER_SECTION = parseInt(sampleVal, 10) || 10;

    for (let i = 0; i < events.length; i++) {
        if(stopRequested) break;
        
        const evt = events[i];
        const sectionDuration = evt.end - evt.start;
        if (sectionDuration <= 0.05) continue; // 短すぎる区間はスキップ

        const aggregator = new VoteAggregator();
        // Hold/Nextも多数決をとるための簡易集計
        const holdCounts = {};
        const nextCounts = {}; // JSON stringifyしてキーにする

        // 区間をN等分してサンプリング
        const step = sectionDuration / (SAMPLES_PER_SECTION + 1);
        for (let k = 1; k <= SAMPLES_PER_SECTION; k++) {
            const t = evt.start + (step * k);
            
            video.currentTime = t;
            await new Promise(r => { video.onseeked = r; });
            
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth; tempCanvas.height = video.videoHeight;
            tempCanvas.getContext('2d').drawImage(video, 0, 0);
            const { canvas: pCanvas, cropData } = processImageTo1080p(tempCanvas);
            
            // フル解析 (ONNXあり)
            const rawData = await analyzePlayerRaw(pCanvas, tempCanvas, cropData, CONFIG[playerId]);
            
            aggregator.add(rawData.board);
            
            // Hold集計
            const hKey = rawData.hold || 'null';
            holdCounts[hKey] = (holdCounts[hKey] || 0) + 1;
            
            // Next集計
            const nKey = JSON.stringify(rawData.next);
            nextCounts[nKey] = (nextCounts[nKey] || 0) + 1;
        }

        // 多数決結果の取得
        const winnerBoard = aggregator.getWinnerBoard();
        if (winnerBoard) {
            // 最頻Hold
            const bestHold = Object.keys(holdCounts).reduce((a, b) => holdCounts[a] > holdCounts[b] ? a : b);
            // 最頻Next
            const bestNextJson = Object.keys(nextCounts).reduce((a, b) => nextCounts[a] > nextCounts[b] ? a : b);
            
            const cleanedBoard = cleanUpBoard(winnerBoard);
            
            timeline.push({
                time: evt.end,
                board: cleanedBoard,
                hold: (bestHold === 'null' ? null : bestHold),
                next: JSON.parse(bestNextJson).join('')
            });
        }

        const pct = 50 + Math.floor((i / events.length) * 50);
        progressEl.value = pct;
        statusEl.textContent = `Analyzing... ${Math.floor(i/events.length*100)}%`;
    }

    return timeline;
}
// ボードの事後処理 (Full Board化, ガベージ処理, 浮遊ブロック除去)
function cleanUpBoard(board20) {
    // 20行 -> 40行拡張
    const fullBoard = Array.from({ length: 40 }, () => Array(10).fill(null));
    for(let r=0; r<20; r++) fullBoard[20+r] = board20[r];

    // 1. Garbage cleanup (既存ロジック: 最下段の非G行より上のGを消す)
    let firstNonGarbageRowFromBottom = -1;
    for (let y = 39; y >= 0; y--) { 
        if (!fullBoard[y].includes('G')) { firstNonGarbageRowFromBottom = y;
        break; } 
    }
    if (firstNonGarbageRowFromBottom !== -1) { 
        for (let y = firstNonGarbageRowFromBottom - 1; y >= 0; y--) { 
            for (let x = 0; x < 10; x++) { if (fullBoard[y][x] === 'G') fullBoard[y][x] = null;
            } 
        } 
    }

    // 2. Floating block removal (新規追加: 空行より上のブロックを全削除)
    // 下(39)から上(0)へスキャンし、完全に空の行が見つかったら、それより上の行をすべてクリアする
    let foundEmptyLine = false;
    for (let y = 39; y >= 0; y--) {
        const isRowEmpty = fullBoard[y].every(cell => cell === null);
        
        if (isRowEmpty) {
            foundEmptyLine = true;
        }
        
        if (foundEmptyLine) {
            // 空行到達以降（より上の行）はすべて消去
            fullBoard[y].fill(null);
        }
    }

    return fullBoard;
}

// ==========================================
//  Fumen Serialization (Tetofu v2 Logic)
// ==========================================

const BOARD_WIDTH = 10;
const BOARD_HEIGHT = 40;

function boardToString1D(board) {
    // 2D Array to 1D Array with '_' for null
    const res = [];
    for(let y=0; y<BOARD_HEIGHT; y++) {
        for(let x=0; x<BOARD_WIDTH; x++) {
            res.push(board[y][x] === null ? '_' : board[y][x]);
        }
    }
    return res;
}

function encodeRLE(data) {
    if (!data || data.length === 0) return [];
    const rle = [];
    let lastValue = data[0];
    let count = 1;
    for (let i = 1; i < data.length; i++) {
        const currentValue = data[i];
        if (currentValue === lastValue) { count++; } 
        else {
            rle.push([lastValue, count]);
            lastValue = currentValue;
            count = 1;
        }
    }
    rle.push([lastValue, count]);
    return rle;
}

function getDifference(prev1D, curr1D) {
    const diff = [];
    for (let i = 0; i < prev1D.length; i++) {
        const prev = prev1D[i], curr = curr1D[i];
        diff.push(prev === curr ? 'E' : curr);
    }
    return diff;
}

function generateFumenUrl(p1Timeline, p2Timeline) {
    // 1. マージして時系列順のイベントリストを作る
    // 構造: { time, p1State, p2State }
    // 重複時間は除去する
    const allTimes = new Set([...p1Timeline.map(e=>e.time), ...p2Timeline.map(e=>e.time)]);
    const sortedTimes = Array.from(allTimes).sort((a,b) => a-b);
    
    // データ構築用のポインタ
    let p1Idx = 0, p2Idx = 0;
    
    const pages = [];
    let prevP1Board1D = null;
    let prevP2Board1D = null;

    for (let i = 0; i < sortedTimes.length; i++) {
        const t = sortedTimes[i];
        
        // この時刻tにおいて有効な最新の状態を取得する
        // p1Timelineの中で time <= t である最後の要素を探す
        while(p1Idx < p1Timeline.length - 1 && p1Timeline[p1Idx+1].time <= t) { p1Idx++; }
        while(p2Idx < p2Timeline.length - 1 && p2Timeline[p2Idx+1].time <= t) { p2Idx++; }
        
        const p1Data = p1Timeline[p1Idx];
        const p2Data = p2Timeline[p2Idx];
        
        // ページデータ作成
        const page = { p1: {}, p2: {} };
        
        // P1処理
        const p1Board1D = boardToString1D(p1Data.board);
        if (i === 0) {
            page.p1.b = encodeRLE(p1Board1D);
        } else {
            const diff = getDifference(prevP1Board1D, p1Board1D);
            page.p1.b = encodeRLE(diff);
        }
        page.p1.h = p1Data.hold || '';
        page.p1.n = p1Data.next || '';
        prevP1Board1D = p1Board1D;
        
        // P2処理
        const p2Board1D = boardToString1D(p2Data.board);
        if (i === 0) {
            page.p2.b = encodeRLE(p2Board1D);
        } else {
            const diff = getDifference(prevP2Board1D, p2Board1D);
            page.p2.b = encodeRLE(diff);
        }
        page.p2.h = p2Data.hold || '';
        page.p2.n = p2Data.next || '';
        prevP2Board1D = p2Board1D;

        pages.push(page);
    }

    const exportObj = {
        v: 'f2',
        m: '2P',
        p: pages
    };

    const jsonString = JSON.stringify(exportObj);
    const uint8Array = new TextEncoder().encode(jsonString);
    const base64Data = btoa(String.fromCharCode.apply(null, uint8Array));
    
    return `https://selmtoe.github.io/Tetris_Simulator/F/index.html#${base64Data}`;
}

</script>
</body>
</html>
